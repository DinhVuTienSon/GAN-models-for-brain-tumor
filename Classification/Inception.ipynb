{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer learning and train inceptionv3 model on case 1: Real images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x) \n",
    "predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "X_final, X_val, y_final, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_final, y_final,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('inception_case_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer learning and train inceptionv3 model on case 2: Real images and data augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# Data augmentation setup\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, height_shift_range=0.2, zoom_range=0.2)\n",
    "\n",
    "# Generate 200 augmented images for each class\n",
    "X_augmented = []\n",
    "y_augmented = []\n",
    "for class_name in class_names:\n",
    "    class_idx = class_names.index(class_name)\n",
    "    class_images = X[y == class_idx]\n",
    "    class_labels = y[y == class_idx]\n",
    "    \n",
    "    augmented_images = datagen.flow(class_images, class_labels, batch_size=1, shuffle=False)\n",
    "    \n",
    "    for _ in range(200):\n",
    "        aug_img, aug_label = augmented_images.next()\n",
    "        X_augmented.append(aug_img[0])\n",
    "        y_augmented.append(aug_label[0])\n",
    "\n",
    "X_augmented = np.array(X_augmented)\n",
    "y_augmented = np.array(y_augmented)\n",
    "\n",
    "X_combined = np.concatenate((X, X_augmented), axis=0)\n",
    "y_combined = np.concatenate((y, y_augmented), axis=0)\n",
    "\n",
    "X_final2, X_val2, y_final2, y_val2 = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.6)(x) \n",
    "predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(\n",
    "    X_final2, y_final2,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val2, y_val2),\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('inception_case_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer learning and train inceptionv3 model on case 3: Real images and generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "gen_dir = 'C:/brain_tumor/version2/notebook/generated_dataset'\n",
    "class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "X_generated = []\n",
    "y_generated = []\n",
    "\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    gen_class_dir = os.path.join(gen_dir, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "    for image_name in os.listdir(gen_class_dir):\n",
    "        image_path = os.path.join(gen_class_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        X_generated.append(image)\n",
    "        y_generated.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_generated = np.array(X_generated)\n",
    "y_generated = np.array(y_generated)\n",
    "\n",
    "X = X.astype('float32') / 255.0\n",
    "X_generated = X_generated.astype('float32') / 255.0\n",
    "\n",
    "X_train_combined = np.concatenate((X, X_generated), axis=0)\n",
    "y_train_combined = np.concatenate((y, y_generated), axis=0)\n",
    "\n",
    "shuffle_indices = np.random.permutation(len(X_train_combined))\n",
    "X_train_combined_shuffled = X_train_combined[shuffle_indices]\n",
    "y_train_combined_shuffled = y_train_combined[shuffle_indices]\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.7)(x)  \n",
    "predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "X_final1, X_val1, y_final1, y_val1 = train_test_split(X_train_combined_shuffled, y_train_combined_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate=0.0002), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(\n",
    "    X_final1, y_final1,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val1, y_val1),\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('inception_case_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code blocks are just my testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "461/461 [==============================] - 19s 32ms/step - loss: 0.8442 - accuracy: 0.6229 - val_loss: 0.7014 - val_accuracy: 0.6876\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 13s 28ms/step - loss: 0.7055 - accuracy: 0.6961 - val_loss: 0.6348 - val_accuracy: 0.7419\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.6650 - accuracy: 0.7162 - val_loss: 0.6049 - val_accuracy: 0.7462\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.6134 - accuracy: 0.7450 - val_loss: 0.5748 - val_accuracy: 0.7636\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.5816 - accuracy: 0.7558 - val_loss: 0.5452 - val_accuracy: 0.7896\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.5596 - accuracy: 0.7640 - val_loss: 0.5673 - val_accuracy: 0.7809\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.5440 - accuracy: 0.7727 - val_loss: 0.5083 - val_accuracy: 0.7852\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.5156 - accuracy: 0.7846 - val_loss: 0.5899 - val_accuracy: 0.7549\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.5083 - accuracy: 0.7819 - val_loss: 0.4986 - val_accuracy: 0.8048\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.4805 - accuracy: 0.7949 - val_loss: 0.5183 - val_accuracy: 0.7918\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.4822 - accuracy: 0.8068 - val_loss: 0.4947 - val_accuracy: 0.7961\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.4656 - accuracy: 0.8079 - val_loss: 0.4856 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.4507 - accuracy: 0.8133 - val_loss: 0.4530 - val_accuracy: 0.8134\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.4448 - accuracy: 0.8237 - val_loss: 0.4675 - val_accuracy: 0.7983\n",
      "Epoch 15/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.4219 - accuracy: 0.8188 - val_loss: 0.4627 - val_accuracy: 0.8243\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.4218 - accuracy: 0.8258 - val_loss: 0.4353 - val_accuracy: 0.8308\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.4087 - accuracy: 0.8269 - val_loss: 0.4241 - val_accuracy: 0.8134\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.3958 - accuracy: 0.8323 - val_loss: 0.4515 - val_accuracy: 0.8134\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.3797 - accuracy: 0.8345 - val_loss: 0.5321 - val_accuracy: 0.7939\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3780 - accuracy: 0.8367 - val_loss: 0.4212 - val_accuracy: 0.8265\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.3798 - accuracy: 0.8470 - val_loss: 0.4144 - val_accuracy: 0.8156\n",
      "Epoch 22/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.3497 - accuracy: 0.8524 - val_loss: 0.4219 - val_accuracy: 0.8373\n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3539 - accuracy: 0.8546 - val_loss: 0.4417 - val_accuracy: 0.8221\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3513 - accuracy: 0.8611 - val_loss: 0.4182 - val_accuracy: 0.8308\n",
      "Epoch 25/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3565 - accuracy: 0.8562 - val_loss: 0.4076 - val_accuracy: 0.8373\n",
      "Epoch 26/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3208 - accuracy: 0.8671 - val_loss: 0.4343 - val_accuracy: 0.8221\n",
      "Epoch 27/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.3209 - accuracy: 0.8741 - val_loss: 0.3689 - val_accuracy: 0.8568\n",
      "Epoch 28/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.3280 - accuracy: 0.8627 - val_loss: 0.3890 - val_accuracy: 0.8395\n",
      "Epoch 29/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.3134 - accuracy: 0.8714 - val_loss: 0.3923 - val_accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.3115 - accuracy: 0.8736 - val_loss: 0.4220 - val_accuracy: 0.8265\n",
      "Epoch 31/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2971 - accuracy: 0.8692 - val_loss: 0.4306 - val_accuracy: 0.8416\n",
      "Epoch 32/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.3030 - accuracy: 0.8828 - val_loss: 0.3886 - val_accuracy: 0.8351\n",
      "Epoch 33/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.2719 - accuracy: 0.8893 - val_loss: 0.3967 - val_accuracy: 0.8482\n",
      "Epoch 34/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2768 - accuracy: 0.8931 - val_loss: 0.4873 - val_accuracy: 0.8069\n",
      "Epoch 35/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.2856 - accuracy: 0.8790 - val_loss: 0.3793 - val_accuracy: 0.8568\n",
      "Epoch 36/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2843 - accuracy: 0.8833 - val_loss: 0.3706 - val_accuracy: 0.8590\n",
      "Epoch 37/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.2738 - accuracy: 0.8882 - val_loss: 0.3777 - val_accuracy: 0.8460\n",
      "Epoch 38/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.2712 - accuracy: 0.8915 - val_loss: 0.3687 - val_accuracy: 0.8482\n",
      "Epoch 39/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2682 - accuracy: 0.8877 - val_loss: 0.3876 - val_accuracy: 0.8482\n",
      "Epoch 40/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2616 - accuracy: 0.8937 - val_loss: 0.3716 - val_accuracy: 0.8633\n",
      "Epoch 41/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.2583 - accuracy: 0.8969 - val_loss: 0.3714 - val_accuracy: 0.8568\n",
      "Epoch 42/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.2429 - accuracy: 0.9040 - val_loss: 0.3763 - val_accuracy: 0.8482\n",
      "Epoch 43/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2389 - accuracy: 0.9067 - val_loss: 0.3747 - val_accuracy: 0.8286\n",
      "Epoch 44/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2449 - accuracy: 0.8980 - val_loss: 0.3543 - val_accuracy: 0.8612\n",
      "Epoch 45/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2359 - accuracy: 0.9050 - val_loss: 0.3800 - val_accuracy: 0.8482\n",
      "Epoch 46/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2302 - accuracy: 0.8974 - val_loss: 0.3501 - val_accuracy: 0.8742\n",
      "Epoch 47/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.2271 - accuracy: 0.9067 - val_loss: 0.4127 - val_accuracy: 0.8460\n",
      "Epoch 48/100\n",
      "461/461 [==============================] - 13s 29ms/step - loss: 0.2214 - accuracy: 0.9116 - val_loss: 0.3613 - val_accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.2117 - accuracy: 0.9137 - val_loss: 0.3694 - val_accuracy: 0.8612\n",
      "Epoch 50/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2285 - accuracy: 0.9083 - val_loss: 0.3855 - val_accuracy: 0.8547\n",
      "Epoch 51/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2208 - accuracy: 0.9034 - val_loss: 0.3619 - val_accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2139 - accuracy: 0.9099 - val_loss: 0.3588 - val_accuracy: 0.8590\n",
      "Epoch 53/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2035 - accuracy: 0.9208 - val_loss: 0.3901 - val_accuracy: 0.8547\n",
      "Epoch 54/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2028 - accuracy: 0.9175 - val_loss: 0.3883 - val_accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.2073 - accuracy: 0.9164 - val_loss: 0.3955 - val_accuracy: 0.8525\n",
      "Epoch 56/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1872 - accuracy: 0.9273 - val_loss: 0.3307 - val_accuracy: 0.8590\n",
      "Epoch 57/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1917 - accuracy: 0.9192 - val_loss: 0.3385 - val_accuracy: 0.8742\n",
      "Epoch 58/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.1885 - accuracy: 0.9197 - val_loss: 0.3736 - val_accuracy: 0.8677\n",
      "Epoch 59/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1923 - accuracy: 0.9202 - val_loss: 0.3797 - val_accuracy: 0.8742\n",
      "Epoch 60/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1937 - accuracy: 0.9262 - val_loss: 0.3703 - val_accuracy: 0.8568\n",
      "Epoch 61/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1892 - accuracy: 0.9230 - val_loss: 0.4247 - val_accuracy: 0.8612\n",
      "Epoch 62/100\n",
      "461/461 [==============================] - 14s 29ms/step - loss: 0.1861 - accuracy: 0.9278 - val_loss: 0.3705 - val_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1744 - accuracy: 0.9360 - val_loss: 0.3771 - val_accuracy: 0.8764\n",
      "Epoch 64/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1652 - accuracy: 0.9349 - val_loss: 0.3985 - val_accuracy: 0.8568\n",
      "Epoch 65/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1768 - accuracy: 0.9267 - val_loss: 0.3704 - val_accuracy: 0.8590\n",
      "Epoch 66/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1748 - accuracy: 0.9284 - val_loss: 0.3916 - val_accuracy: 0.8547\n",
      "Epoch 67/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1751 - accuracy: 0.9273 - val_loss: 0.3817 - val_accuracy: 0.8677\n",
      "Epoch 68/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1537 - accuracy: 0.9371 - val_loss: 0.4373 - val_accuracy: 0.8633\n",
      "Epoch 69/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1748 - accuracy: 0.9235 - val_loss: 0.3729 - val_accuracy: 0.8677\n",
      "Epoch 70/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1665 - accuracy: 0.9262 - val_loss: 0.3667 - val_accuracy: 0.8612\n",
      "Epoch 71/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1748 - accuracy: 0.9267 - val_loss: 0.3701 - val_accuracy: 0.8764\n",
      "Epoch 72/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1401 - accuracy: 0.9414 - val_loss: 0.3960 - val_accuracy: 0.8720\n",
      "Epoch 73/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1438 - accuracy: 0.9441 - val_loss: 0.4016 - val_accuracy: 0.8655\n",
      "Epoch 74/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1547 - accuracy: 0.9354 - val_loss: 0.3973 - val_accuracy: 0.8633\n",
      "Epoch 75/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1426 - accuracy: 0.9376 - val_loss: 0.4192 - val_accuracy: 0.8612\n",
      "Epoch 76/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1478 - accuracy: 0.9376 - val_loss: 0.3801 - val_accuracy: 0.8677\n",
      "Epoch 77/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1265 - accuracy: 0.9485 - val_loss: 0.4285 - val_accuracy: 0.8698\n",
      "Epoch 78/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1380 - accuracy: 0.9457 - val_loss: 0.3887 - val_accuracy: 0.8850\n",
      "Epoch 79/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1383 - accuracy: 0.9436 - val_loss: 0.3597 - val_accuracy: 0.8872\n",
      "Epoch 80/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1350 - accuracy: 0.9485 - val_loss: 0.3603 - val_accuracy: 0.8829\n",
      "Epoch 81/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1404 - accuracy: 0.9468 - val_loss: 0.4034 - val_accuracy: 0.8655\n",
      "Epoch 82/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1571 - accuracy: 0.9354 - val_loss: 0.4044 - val_accuracy: 0.8785\n",
      "Epoch 83/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1312 - accuracy: 0.9436 - val_loss: 0.3852 - val_accuracy: 0.8894\n",
      "Epoch 84/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1294 - accuracy: 0.9485 - val_loss: 0.3931 - val_accuracy: 0.8764\n",
      "Epoch 85/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1477 - accuracy: 0.9403 - val_loss: 0.3649 - val_accuracy: 0.8655\n",
      "Epoch 86/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1405 - accuracy: 0.9392 - val_loss: 0.4164 - val_accuracy: 0.8547\n",
      "Epoch 87/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1125 - accuracy: 0.9550 - val_loss: 0.4308 - val_accuracy: 0.8720\n",
      "Epoch 88/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1189 - accuracy: 0.9495 - val_loss: 0.3650 - val_accuracy: 0.8959\n",
      "Epoch 89/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1259 - accuracy: 0.9495 - val_loss: 0.4441 - val_accuracy: 0.8785\n",
      "Epoch 90/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1209 - accuracy: 0.9582 - val_loss: 0.3965 - val_accuracy: 0.8807\n",
      "Epoch 91/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1144 - accuracy: 0.9533 - val_loss: 0.4925 - val_accuracy: 0.8612\n",
      "Epoch 92/100\n",
      "461/461 [==============================] - 15s 33ms/step - loss: 0.1139 - accuracy: 0.9555 - val_loss: 0.3756 - val_accuracy: 0.8850\n",
      "Epoch 93/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1310 - accuracy: 0.9479 - val_loss: 0.4282 - val_accuracy: 0.8677\n",
      "Epoch 94/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.1330 - accuracy: 0.9447 - val_loss: 0.3890 - val_accuracy: 0.8742\n",
      "Epoch 95/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1310 - accuracy: 0.9457 - val_loss: 0.4115 - val_accuracy: 0.8590\n",
      "Epoch 96/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1077 - accuracy: 0.9620 - val_loss: 0.3724 - val_accuracy: 0.8807\n",
      "Epoch 97/100\n",
      "461/461 [==============================] - 15s 32ms/step - loss: 0.1559 - accuracy: 0.9322 - val_loss: 0.4654 - val_accuracy: 0.8785\n",
      "Epoch 98/100\n",
      "461/461 [==============================] - 14s 31ms/step - loss: 0.0997 - accuracy: 0.9588 - val_loss: 0.4247 - val_accuracy: 0.8677\n",
      "Epoch 99/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1012 - accuracy: 0.9571 - val_loss: 0.4582 - val_accuracy: 0.8655\n",
      "Epoch 100/100\n",
      "461/461 [==============================] - 14s 30ms/step - loss: 0.1240 - accuracy: 0.9523 - val_loss: 0.4507 - val_accuracy: 0.8742\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.4917 - accuracy: 0.8733\n",
      "Test accuracy for Case-3a: 0.8732638955116272\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/classify_dataset'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_train])\n",
    "# X_test = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_test])\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)  # Reduce overfitting\n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# X_final, X_val, y_final, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_final, y_final,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     batch_size=4\n",
    "# )\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=4)\n",
    "# print(f\"Test accuracy for Case-3a: {test_acc}\")\n",
    "\n",
    "# # Save the trained model\n",
    "# # model.save(\"case_3a_trained_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"100e_inception(case3a).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# loaded_model = load_model(\"100e_inception(case3a).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 33ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "# y_pred = loaded_model.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "639/639 [==============================] - 32s 30ms/step - loss: 1.0507 - accuracy: 0.6071 - val_loss: 0.8958 - val_accuracy: 0.6870\n",
      "Epoch 2/100\n",
      "639/639 [==============================] - 18s 28ms/step - loss: 0.8835 - accuracy: 0.6745 - val_loss: 0.7692 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "639/639 [==============================] - 18s 27ms/step - loss: 0.8208 - accuracy: 0.7184 - val_loss: 0.7174 - val_accuracy: 0.7668\n",
      "Epoch 4/100\n",
      "639/639 [==============================] - 17s 27ms/step - loss: 0.7819 - accuracy: 0.7148 - val_loss: 0.7118 - val_accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "639/639 [==============================] - 18s 28ms/step - loss: 0.7473 - accuracy: 0.7242 - val_loss: 0.6646 - val_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.7238 - accuracy: 0.7250 - val_loss: 0.6577 - val_accuracy: 0.7950\n",
      "Epoch 7/100\n",
      "639/639 [==============================] - 18s 28ms/step - loss: 0.7019 - accuracy: 0.7493 - val_loss: 0.6274 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.6831 - accuracy: 0.7466 - val_loss: 0.6381 - val_accuracy: 0.7919\n",
      "Epoch 9/100\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.6546 - accuracy: 0.7618 - val_loss: 0.5989 - val_accuracy: 0.7934\n",
      "Epoch 10/100\n",
      "639/639 [==============================] - 18s 28ms/step - loss: 0.6499 - accuracy: 0.7556 - val_loss: 0.5815 - val_accuracy: 0.7840\n",
      "Epoch 11/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6441 - accuracy: 0.7603 - val_loss: 0.5690 - val_accuracy: 0.7997\n",
      "Epoch 12/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6336 - accuracy: 0.7607 - val_loss: 0.5703 - val_accuracy: 0.7872\n",
      "Epoch 13/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.6092 - accuracy: 0.7701 - val_loss: 0.5647 - val_accuracy: 0.8075\n",
      "Epoch 14/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6065 - accuracy: 0.7775 - val_loss: 0.5583 - val_accuracy: 0.8044\n",
      "Epoch 15/100\n",
      "639/639 [==============================] - 19s 31ms/step - loss: 0.6037 - accuracy: 0.7724 - val_loss: 0.5952 - val_accuracy: 0.7793\n",
      "Epoch 16/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.5904 - accuracy: 0.7838 - val_loss: 0.5452 - val_accuracy: 0.8059\n",
      "Epoch 17/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.5853 - accuracy: 0.7881 - val_loss: 0.5511 - val_accuracy: 0.8044\n",
      "Epoch 18/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5700 - accuracy: 0.7995 - val_loss: 0.5422 - val_accuracy: 0.8122\n",
      "Epoch 19/100\n",
      "639/639 [==============================] - 21s 34ms/step - loss: 0.5791 - accuracy: 0.7873 - val_loss: 0.5375 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.5722 - accuracy: 0.7928 - val_loss: 0.5395 - val_accuracy: 0.8138\n",
      "Epoch 21/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.5771 - accuracy: 0.7854 - val_loss: 0.5393 - val_accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5637 - accuracy: 0.7885 - val_loss: 0.5345 - val_accuracy: 0.8075\n",
      "Epoch 23/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5602 - accuracy: 0.7936 - val_loss: 0.5187 - val_accuracy: 0.8091\n",
      "Epoch 24/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5366 - accuracy: 0.7987 - val_loss: 0.5215 - val_accuracy: 0.8091\n",
      "Epoch 25/100\n",
      "639/639 [==============================] - 24s 37ms/step - loss: 0.5444 - accuracy: 0.8057 - val_loss: 0.5375 - val_accuracy: 0.8044\n",
      "Epoch 26/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5527 - accuracy: 0.7998 - val_loss: 0.5177 - val_accuracy: 0.8122\n",
      "Epoch 27/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5526 - accuracy: 0.7936 - val_loss: 0.5358 - val_accuracy: 0.8169\n",
      "Epoch 28/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5287 - accuracy: 0.8128 - val_loss: 0.5244 - val_accuracy: 0.8106\n",
      "Epoch 29/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5204 - accuracy: 0.8100 - val_loss: 0.5272 - val_accuracy: 0.8153\n",
      "Epoch 30/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.5168 - accuracy: 0.8100 - val_loss: 0.5083 - val_accuracy: 0.8263\n",
      "Epoch 31/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5281 - accuracy: 0.8163 - val_loss: 0.5100 - val_accuracy: 0.8247\n",
      "Epoch 32/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5302 - accuracy: 0.8089 - val_loss: 0.5421 - val_accuracy: 0.8169\n",
      "Epoch 33/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.5288 - accuracy: 0.8077 - val_loss: 0.5633 - val_accuracy: 0.8075\n",
      "Epoch 34/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5251 - accuracy: 0.8143 - val_loss: 0.5141 - val_accuracy: 0.8091\n",
      "Epoch 35/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5251 - accuracy: 0.8132 - val_loss: 0.5216 - val_accuracy: 0.8075\n",
      "Epoch 36/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5301 - accuracy: 0.8085 - val_loss: 0.5112 - val_accuracy: 0.8169\n",
      "Epoch 37/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5029 - accuracy: 0.8218 - val_loss: 0.5658 - val_accuracy: 0.7934\n",
      "Epoch 38/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5035 - accuracy: 0.8218 - val_loss: 0.5128 - val_accuracy: 0.8075\n",
      "Epoch 39/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5126 - accuracy: 0.8233 - val_loss: 0.5113 - val_accuracy: 0.8294\n",
      "Epoch 40/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5109 - accuracy: 0.8233 - val_loss: 0.5043 - val_accuracy: 0.8247\n",
      "Epoch 41/100\n",
      "639/639 [==============================] - 23s 37ms/step - loss: 0.5124 - accuracy: 0.8175 - val_loss: 0.5040 - val_accuracy: 0.8326\n",
      "Epoch 42/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5098 - accuracy: 0.8143 - val_loss: 0.5029 - val_accuracy: 0.8200\n",
      "Epoch 43/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4980 - accuracy: 0.8202 - val_loss: 0.5185 - val_accuracy: 0.8169\n",
      "Epoch 44/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4973 - accuracy: 0.8159 - val_loss: 0.5063 - val_accuracy: 0.8294\n",
      "Epoch 45/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4897 - accuracy: 0.8288 - val_loss: 0.5021 - val_accuracy: 0.8294\n",
      "Epoch 46/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.5026 - accuracy: 0.8269 - val_loss: 0.5278 - val_accuracy: 0.8013\n",
      "Epoch 47/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5097 - accuracy: 0.8061 - val_loss: 0.5425 - val_accuracy: 0.8185\n",
      "Epoch 48/100\n",
      "639/639 [==============================] - 21s 34ms/step - loss: 0.4915 - accuracy: 0.8308 - val_loss: 0.5072 - val_accuracy: 0.8263\n",
      "Epoch 49/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5049 - accuracy: 0.8288 - val_loss: 0.4978 - val_accuracy: 0.8185\n",
      "Epoch 50/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4986 - accuracy: 0.8214 - val_loss: 0.4988 - val_accuracy: 0.8216\n",
      "Epoch 51/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4878 - accuracy: 0.8300 - val_loss: 0.4895 - val_accuracy: 0.8247\n",
      "Epoch 52/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4791 - accuracy: 0.8249 - val_loss: 0.5024 - val_accuracy: 0.8232\n",
      "Epoch 53/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5046 - accuracy: 0.8206 - val_loss: 0.5325 - val_accuracy: 0.8059\n",
      "Epoch 54/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4821 - accuracy: 0.8343 - val_loss: 0.5133 - val_accuracy: 0.8138\n",
      "Epoch 55/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4789 - accuracy: 0.8269 - val_loss: 0.5066 - val_accuracy: 0.8326\n",
      "Epoch 56/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4918 - accuracy: 0.8241 - val_loss: 0.5007 - val_accuracy: 0.8200\n",
      "Epoch 57/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4910 - accuracy: 0.8269 - val_loss: 0.5108 - val_accuracy: 0.8169\n",
      "Epoch 58/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4765 - accuracy: 0.8261 - val_loss: 0.4908 - val_accuracy: 0.8232\n",
      "Epoch 59/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4867 - accuracy: 0.8292 - val_loss: 0.4913 - val_accuracy: 0.8263\n",
      "Epoch 60/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4683 - accuracy: 0.8343 - val_loss: 0.5320 - val_accuracy: 0.8138\n",
      "Epoch 61/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4921 - accuracy: 0.8230 - val_loss: 0.4939 - val_accuracy: 0.8310\n",
      "Epoch 62/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4749 - accuracy: 0.8331 - val_loss: 0.4842 - val_accuracy: 0.8216\n",
      "Epoch 63/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4877 - accuracy: 0.8292 - val_loss: 0.4884 - val_accuracy: 0.8232\n",
      "Epoch 64/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4748 - accuracy: 0.8410 - val_loss: 0.5143 - val_accuracy: 0.8169\n",
      "Epoch 65/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4869 - accuracy: 0.8347 - val_loss: 0.5093 - val_accuracy: 0.8185\n",
      "Epoch 66/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4796 - accuracy: 0.8233 - val_loss: 0.4971 - val_accuracy: 0.8263\n",
      "Epoch 67/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4715 - accuracy: 0.8378 - val_loss: 0.4893 - val_accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4715 - accuracy: 0.8316 - val_loss: 0.5158 - val_accuracy: 0.8013\n",
      "Epoch 69/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4744 - accuracy: 0.8296 - val_loss: 0.4864 - val_accuracy: 0.8247\n",
      "Epoch 70/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4667 - accuracy: 0.8335 - val_loss: 0.4865 - val_accuracy: 0.8169\n",
      "Epoch 71/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4771 - accuracy: 0.8284 - val_loss: 0.4821 - val_accuracy: 0.8294\n",
      "Epoch 72/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4545 - accuracy: 0.8461 - val_loss: 0.5354 - val_accuracy: 0.8059\n",
      "Epoch 73/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4673 - accuracy: 0.8367 - val_loss: 0.4888 - val_accuracy: 0.8341\n",
      "Epoch 74/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4673 - accuracy: 0.8335 - val_loss: 0.5008 - val_accuracy: 0.8263\n",
      "Epoch 75/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4737 - accuracy: 0.8394 - val_loss: 0.5080 - val_accuracy: 0.8216\n",
      "Epoch 76/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4739 - accuracy: 0.8371 - val_loss: 0.5093 - val_accuracy: 0.8279\n",
      "Epoch 77/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4642 - accuracy: 0.8331 - val_loss: 0.4877 - val_accuracy: 0.8326\n",
      "Epoch 78/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4741 - accuracy: 0.8304 - val_loss: 0.4788 - val_accuracy: 0.8326\n",
      "Epoch 79/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4733 - accuracy: 0.8386 - val_loss: 0.4858 - val_accuracy: 0.8263\n",
      "Epoch 80/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4542 - accuracy: 0.8433 - val_loss: 0.5035 - val_accuracy: 0.8138\n",
      "Epoch 81/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4703 - accuracy: 0.8265 - val_loss: 0.4995 - val_accuracy: 0.8185\n",
      "Epoch 82/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4621 - accuracy: 0.8386 - val_loss: 0.4743 - val_accuracy: 0.8357\n",
      "Epoch 83/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4555 - accuracy: 0.8461 - val_loss: 0.5097 - val_accuracy: 0.8106\n",
      "Epoch 84/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4625 - accuracy: 0.8304 - val_loss: 0.4899 - val_accuracy: 0.8294\n",
      "Epoch 85/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4575 - accuracy: 0.8437 - val_loss: 0.4785 - val_accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "639/639 [==============================] - 21s 34ms/step - loss: 0.4552 - accuracy: 0.8433 - val_loss: 0.4719 - val_accuracy: 0.8372\n",
      "Epoch 87/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.4525 - accuracy: 0.8437 - val_loss: 0.4833 - val_accuracy: 0.8357\n",
      "Epoch 88/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4615 - accuracy: 0.8382 - val_loss: 0.4939 - val_accuracy: 0.8341\n",
      "Epoch 89/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4637 - accuracy: 0.8402 - val_loss: 0.4776 - val_accuracy: 0.8294\n",
      "Epoch 90/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.4541 - accuracy: 0.8418 - val_loss: 0.4876 - val_accuracy: 0.8341\n",
      "Epoch 91/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.4557 - accuracy: 0.8453 - val_loss: 0.4925 - val_accuracy: 0.8388\n",
      "Epoch 92/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.4672 - accuracy: 0.8316 - val_loss: 0.4874 - val_accuracy: 0.8326\n",
      "Epoch 93/100\n",
      "639/639 [==============================] - 23s 36ms/step - loss: 0.4687 - accuracy: 0.8359 - val_loss: 0.4779 - val_accuracy: 0.8404\n",
      "Epoch 94/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4511 - accuracy: 0.8441 - val_loss: 0.4971 - val_accuracy: 0.8341\n",
      "Epoch 95/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4589 - accuracy: 0.8378 - val_loss: 0.4867 - val_accuracy: 0.8232\n",
      "Epoch 96/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4682 - accuracy: 0.8316 - val_loss: 0.4714 - val_accuracy: 0.8435\n",
      "Epoch 97/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4486 - accuracy: 0.8441 - val_loss: 0.4885 - val_accuracy: 0.8326\n",
      "Epoch 98/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4563 - accuracy: 0.8374 - val_loss: 0.4776 - val_accuracy: 0.8372\n",
      "Epoch 99/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.4506 - accuracy: 0.8425 - val_loss: 0.5106 - val_accuracy: 0.8232\n",
      "Epoch 100/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4567 - accuracy: 0.8347 - val_loss: 0.4973 - val_accuracy: 0.8153\n",
      "9/9 [==============================] - 1s 40ms/step - loss: 0.5904 - accuracy: 0.8090\n",
      "Test accuracy for Case-3b: 0.8090277910232544\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/classify_dataset'\n",
    "# gen_dir = 'C:/brain_tumor/version2/notebook/generated_dataset'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# X_generated = []\n",
    "# y_generated = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     gen_class_dir = os.path.join(gen_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "#     for image_name in os.listdir(gen_class_dir):\n",
    "#         image_path = os.path.join(gen_class_dir, image_name)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.resize(image, (128, 128))\n",
    "#         X_generated.append(image)\n",
    "#         y_generated.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# X_generated = np.array(X_generated)\n",
    "# y_generated = np.array(y_generated)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "# X_generated = X_generated.astype('float32') / 255.0\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# X_train = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_train])\n",
    "# X_test = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_test])\n",
    "# X_generated = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_generated])\n",
    "\n",
    "# X_train_combined = np.concatenate((X_train, X_generated), axis=0)\n",
    "# y_train_combined = np.concatenate((y_train, y_generated), axis=0)\n",
    "\n",
    "# shuffle_indices = np.random.permutation(len(X_train_combined))\n",
    "# X_train_combined_shuffled = X_train_combined[shuffle_indices]\n",
    "# y_train_combined_shuffled = y_train_combined[shuffle_indices]\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "# x = Dropout(0.7)(x)  \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# X_final1, X_val1, y_final1, y_val1 = train_test_split(X_train_combined_shuffled, y_train_combined_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "# model1.compile(optimizer=Adam(learning_rate=0.0002), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history1 = model1.fit(\n",
    "#     X_final1, y_final1,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val1, y_val1),\n",
    "#     batch_size=4\n",
    "# )\n",
    "\n",
    "# test_loss1, test_acc1 = model1.evaluate(X_test, y_test)\n",
    "# print(f\"Test accuracy for Case-3b: {test_acc1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.save('100e_inception(case3b_81_acc).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# loaded_model1 = load_model(\"100e_inception(case3b_81_acc).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history1.history['loss'])\n",
    "# plt.plot(history1.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history1.history['accuracy'])\n",
    "# plt.plot(history1.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/classify_dataset'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Data augmentation setup\n",
    "# datagen = ImageDataGenerator(horizontal_flip=True, height_shift_range=0.2, zoom_range=0.2)\n",
    "\n",
    "# # Generate 200 augmented images for each class\n",
    "# X_augmented = []\n",
    "# y_augmented = []\n",
    "# for class_name in class_names:\n",
    "#     class_idx = class_names.index(class_name)\n",
    "#     class_images = X_train[y_train == class_idx]\n",
    "#     class_labels = y_train[y_train == class_idx]\n",
    "    \n",
    "#     augmented_images = datagen.flow(class_images, class_labels, batch_size=1, shuffle=False)\n",
    "    \n",
    "#     for _ in range(200):\n",
    "#         aug_img, aug_label = augmented_images.next()\n",
    "#         X_augmented.append(aug_img[0])\n",
    "#         y_augmented.append(aug_label[0])\n",
    "\n",
    "# X_augmented = np.array(X_augmented)\n",
    "# y_augmented = np.array(y_augmented)\n",
    "\n",
    "# X_combined = np.concatenate((X_train, X_augmented), axis=0)\n",
    "# y_combined = np.concatenate((y_train, y_augmented), axis=0)\n",
    "\n",
    "# X_final2, X_val2, y_final2, y_val2 = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.6)(x) \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# model2.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history2 = model2.fit(\n",
    "#     X_final2, y_final2,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val2, y_val2),\n",
    "#     batch_size=4\n",
    "# )\n",
    "\n",
    "# test_loss2, test_acc2 = model2.evaluate(X_test, y_test)\n",
    "# print(f\"Test accuracy for Case-3a: {test_acc2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save(\"100e_inception(case3c).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# loaded_model2 = load_model(\"100e_inception(case3c).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history2.history['loss'])\n",
    "# plt.plot(history2.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history2.history['accuracy'])\n",
    "# plt.plot(history2.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "# y_pred = loaded_model2.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "639/639 [==============================] - 28s 29ms/step - loss: 1.0714 - accuracy: 0.5856 - val_loss: 0.8372 - val_accuracy: 0.7246\n",
      "Epoch 2/100\n",
      "639/639 [==============================] - 18s 28ms/step - loss: 0.8899 - accuracy: 0.6780 - val_loss: 0.7828 - val_accuracy: 0.7512\n",
      "Epoch 3/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.8318 - accuracy: 0.6937 - val_loss: 0.7585 - val_accuracy: 0.7512\n",
      "Epoch 4/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.7958 - accuracy: 0.7109 - val_loss: 0.6859 - val_accuracy: 0.7700\n",
      "Epoch 5/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.7589 - accuracy: 0.7231 - val_loss: 0.6768 - val_accuracy: 0.7621\n",
      "Epoch 6/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.7336 - accuracy: 0.7329 - val_loss: 0.6597 - val_accuracy: 0.7590\n",
      "Epoch 7/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.7066 - accuracy: 0.7333 - val_loss: 0.6401 - val_accuracy: 0.7480\n",
      "Epoch 8/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6986 - accuracy: 0.7329 - val_loss: 0.6232 - val_accuracy: 0.7746\n",
      "Epoch 9/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.6744 - accuracy: 0.7423 - val_loss: 0.6170 - val_accuracy: 0.7684\n",
      "Epoch 10/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.6714 - accuracy: 0.7571 - val_loss: 0.6158 - val_accuracy: 0.7606\n",
      "Epoch 11/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.6561 - accuracy: 0.7646 - val_loss: 0.6004 - val_accuracy: 0.7840\n",
      "Epoch 12/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.6433 - accuracy: 0.7662 - val_loss: 0.6033 - val_accuracy: 0.7762\n",
      "Epoch 13/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6306 - accuracy: 0.7756 - val_loss: 0.5833 - val_accuracy: 0.7825\n",
      "Epoch 14/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6216 - accuracy: 0.7693 - val_loss: 0.5781 - val_accuracy: 0.7731\n",
      "Epoch 15/100\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.6234 - accuracy: 0.7673 - val_loss: 0.5965 - val_accuracy: 0.7825\n",
      "Epoch 16/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.6174 - accuracy: 0.7669 - val_loss: 0.5734 - val_accuracy: 0.7840\n",
      "Epoch 17/100\n",
      "639/639 [==============================] - 19s 31ms/step - loss: 0.6018 - accuracy: 0.7842 - val_loss: 0.5802 - val_accuracy: 0.7950\n",
      "Epoch 18/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.6060 - accuracy: 0.7787 - val_loss: 0.5683 - val_accuracy: 0.7903\n",
      "Epoch 19/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5889 - accuracy: 0.7928 - val_loss: 0.5615 - val_accuracy: 0.7934\n",
      "Epoch 20/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5931 - accuracy: 0.7873 - val_loss: 0.5566 - val_accuracy: 0.7997\n",
      "Epoch 21/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5814 - accuracy: 0.7873 - val_loss: 0.5501 - val_accuracy: 0.7934\n",
      "Epoch 22/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5752 - accuracy: 0.7948 - val_loss: 0.5525 - val_accuracy: 0.7919\n",
      "Epoch 23/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5726 - accuracy: 0.7932 - val_loss: 0.5532 - val_accuracy: 0.7919\n",
      "Epoch 24/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5755 - accuracy: 0.7904 - val_loss: 0.5527 - val_accuracy: 0.7997\n",
      "Epoch 25/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5739 - accuracy: 0.7940 - val_loss: 0.5527 - val_accuracy: 0.7950\n",
      "Epoch 26/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5508 - accuracy: 0.8045 - val_loss: 0.5414 - val_accuracy: 0.7950\n",
      "Epoch 27/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5606 - accuracy: 0.8018 - val_loss: 0.5463 - val_accuracy: 0.7950\n",
      "Epoch 28/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5575 - accuracy: 0.7904 - val_loss: 0.5756 - val_accuracy: 0.7840\n",
      "Epoch 29/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5626 - accuracy: 0.7951 - val_loss: 0.5554 - val_accuracy: 0.7887\n",
      "Epoch 30/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5593 - accuracy: 0.7971 - val_loss: 0.5358 - val_accuracy: 0.8106\n",
      "Epoch 31/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5533 - accuracy: 0.7975 - val_loss: 0.5428 - val_accuracy: 0.7981\n",
      "Epoch 32/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5440 - accuracy: 0.8053 - val_loss: 0.5519 - val_accuracy: 0.8013\n",
      "Epoch 33/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5402 - accuracy: 0.7998 - val_loss: 0.5504 - val_accuracy: 0.7934\n",
      "Epoch 34/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5374 - accuracy: 0.8085 - val_loss: 0.5498 - val_accuracy: 0.7966\n",
      "Epoch 35/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5475 - accuracy: 0.8136 - val_loss: 0.5319 - val_accuracy: 0.8153\n",
      "Epoch 36/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5499 - accuracy: 0.8026 - val_loss: 0.5249 - val_accuracy: 0.8091\n",
      "Epoch 37/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5456 - accuracy: 0.8018 - val_loss: 0.5243 - val_accuracy: 0.8075\n",
      "Epoch 38/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5336 - accuracy: 0.8092 - val_loss: 0.5169 - val_accuracy: 0.8153\n",
      "Epoch 39/100\n",
      "639/639 [==============================] - 21s 34ms/step - loss: 0.5306 - accuracy: 0.8112 - val_loss: 0.5674 - val_accuracy: 0.7919\n",
      "Epoch 40/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5375 - accuracy: 0.8159 - val_loss: 0.5288 - val_accuracy: 0.8059\n",
      "Epoch 41/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5336 - accuracy: 0.8139 - val_loss: 0.5280 - val_accuracy: 0.8028\n",
      "Epoch 42/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5329 - accuracy: 0.8053 - val_loss: 0.5296 - val_accuracy: 0.8122\n",
      "Epoch 43/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5247 - accuracy: 0.8194 - val_loss: 0.5284 - val_accuracy: 0.8075\n",
      "Epoch 44/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.5213 - accuracy: 0.8249 - val_loss: 0.5203 - val_accuracy: 0.8138\n",
      "Epoch 45/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5141 - accuracy: 0.8206 - val_loss: 0.5165 - val_accuracy: 0.8122\n",
      "Epoch 46/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5156 - accuracy: 0.8116 - val_loss: 0.5250 - val_accuracy: 0.8122\n",
      "Epoch 47/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5076 - accuracy: 0.8163 - val_loss: 0.5280 - val_accuracy: 0.8153\n",
      "Epoch 48/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5073 - accuracy: 0.8245 - val_loss: 0.5165 - val_accuracy: 0.8232\n",
      "Epoch 49/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5262 - accuracy: 0.8132 - val_loss: 0.5278 - val_accuracy: 0.8122\n",
      "Epoch 50/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.5173 - accuracy: 0.8296 - val_loss: 0.5338 - val_accuracy: 0.8059\n",
      "Epoch 51/100\n",
      "639/639 [==============================] - 24s 37ms/step - loss: 0.5088 - accuracy: 0.8300 - val_loss: 0.5451 - val_accuracy: 0.8075\n",
      "Epoch 52/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5127 - accuracy: 0.8190 - val_loss: 0.5610 - val_accuracy: 0.7966\n",
      "Epoch 53/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5061 - accuracy: 0.8214 - val_loss: 0.5671 - val_accuracy: 0.7809\n",
      "Epoch 54/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5163 - accuracy: 0.8179 - val_loss: 0.5764 - val_accuracy: 0.7872\n",
      "Epoch 55/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5066 - accuracy: 0.8226 - val_loss: 0.5169 - val_accuracy: 0.8185\n",
      "Epoch 56/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4961 - accuracy: 0.8237 - val_loss: 0.5308 - val_accuracy: 0.8091\n",
      "Epoch 57/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.5136 - accuracy: 0.8194 - val_loss: 0.5184 - val_accuracy: 0.8200\n",
      "Epoch 58/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4961 - accuracy: 0.8257 - val_loss: 0.5213 - val_accuracy: 0.8247\n",
      "Epoch 59/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.5015 - accuracy: 0.8284 - val_loss: 0.5179 - val_accuracy: 0.8294\n",
      "Epoch 60/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4968 - accuracy: 0.8249 - val_loss: 0.5101 - val_accuracy: 0.8310\n",
      "Epoch 61/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4958 - accuracy: 0.8320 - val_loss: 0.5196 - val_accuracy: 0.8138\n",
      "Epoch 62/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5022 - accuracy: 0.8241 - val_loss: 0.5304 - val_accuracy: 0.8169\n",
      "Epoch 63/100\n",
      "639/639 [==============================] - 24s 37ms/step - loss: 0.4932 - accuracy: 0.8214 - val_loss: 0.5270 - val_accuracy: 0.8185\n",
      "Epoch 64/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4911 - accuracy: 0.8312 - val_loss: 0.5181 - val_accuracy: 0.8310\n",
      "Epoch 65/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.4863 - accuracy: 0.8222 - val_loss: 0.5199 - val_accuracy: 0.8153\n",
      "Epoch 66/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4903 - accuracy: 0.8265 - val_loss: 0.5353 - val_accuracy: 0.8138\n",
      "Epoch 67/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.4829 - accuracy: 0.8261 - val_loss: 0.5528 - val_accuracy: 0.7981\n",
      "Epoch 68/100\n",
      "639/639 [==============================] - 23s 35ms/step - loss: 0.4895 - accuracy: 0.8331 - val_loss: 0.5356 - val_accuracy: 0.8263\n",
      "Epoch 69/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.5124 - accuracy: 0.8269 - val_loss: 0.5277 - val_accuracy: 0.8106\n",
      "Epoch 70/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.5046 - accuracy: 0.8218 - val_loss: 0.5258 - val_accuracy: 0.8169\n",
      "Epoch 71/100\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.4730 - accuracy: 0.8355 - val_loss: 0.5513 - val_accuracy: 0.8091\n",
      "Epoch 72/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4974 - accuracy: 0.8218 - val_loss: 0.5226 - val_accuracy: 0.8153\n",
      "Epoch 73/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4877 - accuracy: 0.8308 - val_loss: 0.5248 - val_accuracy: 0.8326\n",
      "Epoch 74/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4782 - accuracy: 0.8363 - val_loss: 0.5160 - val_accuracy: 0.8153\n",
      "Epoch 75/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4981 - accuracy: 0.8284 - val_loss: 0.5121 - val_accuracy: 0.8247\n",
      "Epoch 76/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4927 - accuracy: 0.8186 - val_loss: 0.5142 - val_accuracy: 0.8294\n",
      "Epoch 77/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4909 - accuracy: 0.8300 - val_loss: 0.5285 - val_accuracy: 0.8279\n",
      "Epoch 78/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4913 - accuracy: 0.8320 - val_loss: 0.5304 - val_accuracy: 0.8185\n",
      "Epoch 79/100\n",
      "639/639 [==============================] - 22s 35ms/step - loss: 0.4862 - accuracy: 0.8343 - val_loss: 0.5140 - val_accuracy: 0.8200\n",
      "Epoch 80/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4894 - accuracy: 0.8273 - val_loss: 0.5136 - val_accuracy: 0.8263\n",
      "Epoch 81/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4828 - accuracy: 0.8320 - val_loss: 0.5200 - val_accuracy: 0.8341\n",
      "Epoch 82/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4853 - accuracy: 0.8339 - val_loss: 0.5352 - val_accuracy: 0.8075\n",
      "Epoch 83/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4814 - accuracy: 0.8425 - val_loss: 0.5035 - val_accuracy: 0.8357\n",
      "Epoch 84/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4775 - accuracy: 0.8390 - val_loss: 0.5222 - val_accuracy: 0.8263\n",
      "Epoch 85/100\n",
      "639/639 [==============================] - 21s 34ms/step - loss: 0.4760 - accuracy: 0.8398 - val_loss: 0.5282 - val_accuracy: 0.8263\n",
      "Epoch 86/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4674 - accuracy: 0.8429 - val_loss: 0.4973 - val_accuracy: 0.8341\n",
      "Epoch 87/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4766 - accuracy: 0.8367 - val_loss: 0.5151 - val_accuracy: 0.8326\n",
      "Epoch 88/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4940 - accuracy: 0.8269 - val_loss: 0.5269 - val_accuracy: 0.8216\n",
      "Epoch 89/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4758 - accuracy: 0.8343 - val_loss: 0.4938 - val_accuracy: 0.8310\n",
      "Epoch 90/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4758 - accuracy: 0.8402 - val_loss: 0.5353 - val_accuracy: 0.8122\n",
      "Epoch 91/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4804 - accuracy: 0.8429 - val_loss: 0.5138 - val_accuracy: 0.8232\n",
      "Epoch 92/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4659 - accuracy: 0.8433 - val_loss: 0.5243 - val_accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4590 - accuracy: 0.8433 - val_loss: 0.4948 - val_accuracy: 0.8513\n",
      "Epoch 94/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4793 - accuracy: 0.8347 - val_loss: 0.5072 - val_accuracy: 0.8372\n",
      "Epoch 95/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4712 - accuracy: 0.8429 - val_loss: 0.5228 - val_accuracy: 0.8263\n",
      "Epoch 96/100\n",
      "639/639 [==============================] - 22s 34ms/step - loss: 0.4789 - accuracy: 0.8378 - val_loss: 0.5183 - val_accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4709 - accuracy: 0.8402 - val_loss: 0.5088 - val_accuracy: 0.8232\n",
      "Epoch 98/100\n",
      "639/639 [==============================] - 21s 32ms/step - loss: 0.4731 - accuracy: 0.8339 - val_loss: 0.4905 - val_accuracy: 0.8451\n",
      "Epoch 99/100\n",
      "639/639 [==============================] - 20s 32ms/step - loss: 0.4740 - accuracy: 0.8320 - val_loss: 0.4932 - val_accuracy: 0.8435\n",
      "Epoch 100/100\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.4608 - accuracy: 0.8468 - val_loss: 0.5036 - val_accuracy: 0.8388\n",
      "9/9 [==============================] - 1s 41ms/step - loss: 0.5010 - accuracy: 0.8472\n",
      "Test accuracy for Case-3b: 0.8472222089767456\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/classify_dataset'\n",
    "# gen_dir = 'C:/brain_tumor/version2/notebook/generated_dataset_1'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# X_generated = []\n",
    "# y_generated = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     gen_class_dir = os.path.join(gen_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "#     for image_name in os.listdir(gen_class_dir):\n",
    "#         image_path = os.path.join(gen_class_dir, image_name)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.resize(image, (128, 128))\n",
    "#         X_generated.append(image)\n",
    "#         y_generated.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# X_generated = np.array(X_generated)\n",
    "# y_generated = np.array(y_generated)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "# X_generated = X_generated.astype('float32') / 255.0\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# X_train = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_train])\n",
    "# X_test = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_test])\n",
    "# X_generated = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_generated])\n",
    "\n",
    "# X_train_combined = np.concatenate((X_train, X_generated), axis=0)\n",
    "# y_train_combined = np.concatenate((y_train, y_generated), axis=0)\n",
    "\n",
    "# shuffle_indices = np.random.permutation(len(X_train_combined))\n",
    "# X_train_combined_shuffled = X_train_combined[shuffle_indices]\n",
    "# y_train_combined_shuffled = y_train_combined[shuffle_indices]\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "# x = Dropout(0.7)(x)  \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# X_final1, X_val1, y_final1, y_val1 = train_test_split(X_train_combined_shuffled, y_train_combined_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "# model1.compile(optimizer=Adam(learning_rate=0.0002), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history1 = model1.fit(\n",
    "#     X_final1, y_final1,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val1, y_val1),\n",
    "#     batch_size=4\n",
    "# )\n",
    "\n",
    "# test_loss1, test_acc1 = model1.evaluate(X_test, y_test)\n",
    "# print(f\"Test accuracy for Case-3b: {test_acc1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "824/824 [==============================] - 32s 29ms/step - loss: 0.7687 - accuracy: 0.6863 - val_loss: 0.5113 - val_accuracy: 0.7718\n",
      "Epoch 2/100\n",
      "824/824 [==============================] - 22s 27ms/step - loss: 0.5044 - accuracy: 0.7944 - val_loss: 0.4362 - val_accuracy: 0.7949\n",
      "Epoch 3/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.4402 - accuracy: 0.8184 - val_loss: 0.4154 - val_accuracy: 0.8374\n",
      "Epoch 4/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.3870 - accuracy: 0.8418 - val_loss: 0.3974 - val_accuracy: 0.8386\n",
      "Epoch 5/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.3530 - accuracy: 0.8551 - val_loss: 0.3722 - val_accuracy: 0.8434\n",
      "Epoch 6/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.3276 - accuracy: 0.8740 - val_loss: 0.3540 - val_accuracy: 0.8495\n",
      "Epoch 7/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.3074 - accuracy: 0.8776 - val_loss: 0.3584 - val_accuracy: 0.8556\n",
      "Epoch 8/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.2801 - accuracy: 0.8855 - val_loss: 0.4549 - val_accuracy: 0.8350\n",
      "Epoch 9/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.2663 - accuracy: 0.8901 - val_loss: 0.3138 - val_accuracy: 0.8629\n",
      "Epoch 10/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.2532 - accuracy: 0.8968 - val_loss: 0.3448 - val_accuracy: 0.8410\n",
      "Epoch 11/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.2588 - accuracy: 0.8955 - val_loss: 0.3094 - val_accuracy: 0.8726\n",
      "Epoch 12/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.2348 - accuracy: 0.9049 - val_loss: 0.3534 - val_accuracy: 0.8617\n",
      "Epoch 13/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.2099 - accuracy: 0.9177 - val_loss: 0.3750 - val_accuracy: 0.8495\n",
      "Epoch 14/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.2141 - accuracy: 0.9113 - val_loss: 0.3683 - val_accuracy: 0.8568\n",
      "Epoch 15/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.2000 - accuracy: 0.9192 - val_loss: 0.3563 - val_accuracy: 0.8629\n",
      "Epoch 16/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1874 - accuracy: 0.9271 - val_loss: 0.3280 - val_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.1814 - accuracy: 0.9247 - val_loss: 0.3228 - val_accuracy: 0.8823\n",
      "Epoch 18/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1756 - accuracy: 0.9283 - val_loss: 0.3205 - val_accuracy: 0.8811\n",
      "Epoch 19/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1669 - accuracy: 0.9268 - val_loss: 0.3478 - val_accuracy: 0.8883\n",
      "Epoch 20/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.1511 - accuracy: 0.9371 - val_loss: 0.3422 - val_accuracy: 0.8883\n",
      "Epoch 21/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1662 - accuracy: 0.9305 - val_loss: 0.3347 - val_accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.1500 - accuracy: 0.9344 - val_loss: 0.3876 - val_accuracy: 0.8835\n",
      "Epoch 23/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.1556 - accuracy: 0.9371 - val_loss: 0.2987 - val_accuracy: 0.8823\n",
      "Epoch 24/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.1494 - accuracy: 0.9393 - val_loss: 0.3093 - val_accuracy: 0.8774\n",
      "Epoch 25/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.1364 - accuracy: 0.9390 - val_loss: 0.4044 - val_accuracy: 0.8859\n",
      "Epoch 26/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.1244 - accuracy: 0.9487 - val_loss: 0.3387 - val_accuracy: 0.8774\n",
      "Epoch 27/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.1332 - accuracy: 0.9441 - val_loss: 0.3685 - val_accuracy: 0.8799\n",
      "Epoch 28/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.1395 - accuracy: 0.9438 - val_loss: 0.3397 - val_accuracy: 0.8847\n",
      "Epoch 29/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.1210 - accuracy: 0.9554 - val_loss: 0.3341 - val_accuracy: 0.8993\n",
      "Epoch 30/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.1358 - accuracy: 0.9429 - val_loss: 0.3993 - val_accuracy: 0.8859\n",
      "Epoch 31/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1175 - accuracy: 0.9523 - val_loss: 0.4116 - val_accuracy: 0.8774\n",
      "Epoch 32/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.1196 - accuracy: 0.9517 - val_loss: 0.4546 - val_accuracy: 0.8799\n",
      "Epoch 33/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.1263 - accuracy: 0.9511 - val_loss: 0.4359 - val_accuracy: 0.8738\n",
      "Epoch 34/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.1131 - accuracy: 0.9499 - val_loss: 0.3665 - val_accuracy: 0.8871\n",
      "Epoch 35/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.1063 - accuracy: 0.9544 - val_loss: 0.3243 - val_accuracy: 0.8944\n",
      "Epoch 36/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1019 - accuracy: 0.9605 - val_loss: 0.3735 - val_accuracy: 0.8956\n",
      "Epoch 37/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0990 - accuracy: 0.9587 - val_loss: 0.3885 - val_accuracy: 0.8871\n",
      "Epoch 38/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0981 - accuracy: 0.9584 - val_loss: 0.4844 - val_accuracy: 0.8859\n",
      "Epoch 39/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.1055 - accuracy: 0.9566 - val_loss: 0.3772 - val_accuracy: 0.8932\n",
      "Epoch 40/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.1040 - accuracy: 0.9587 - val_loss: 0.3929 - val_accuracy: 0.8871\n",
      "Epoch 41/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0914 - accuracy: 0.9630 - val_loss: 0.4189 - val_accuracy: 0.8859\n",
      "Epoch 42/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0952 - accuracy: 0.9548 - val_loss: 0.3723 - val_accuracy: 0.8956\n",
      "Epoch 43/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.1048 - accuracy: 0.9602 - val_loss: 0.4173 - val_accuracy: 0.8920\n",
      "Epoch 44/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0955 - accuracy: 0.9605 - val_loss: 0.3579 - val_accuracy: 0.8908\n",
      "Epoch 45/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0806 - accuracy: 0.9654 - val_loss: 0.4138 - val_accuracy: 0.8908\n",
      "Epoch 46/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.0855 - accuracy: 0.9645 - val_loss: 0.4158 - val_accuracy: 0.8944\n",
      "Epoch 47/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0823 - accuracy: 0.9651 - val_loss: 0.4211 - val_accuracy: 0.8932\n",
      "Epoch 48/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0883 - accuracy: 0.9630 - val_loss: 0.4470 - val_accuracy: 0.8920\n",
      "Epoch 49/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0916 - accuracy: 0.9636 - val_loss: 0.4316 - val_accuracy: 0.8993\n",
      "Epoch 50/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0923 - accuracy: 0.9617 - val_loss: 0.5514 - val_accuracy: 0.8847\n",
      "Epoch 51/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0863 - accuracy: 0.9645 - val_loss: 0.3906 - val_accuracy: 0.9041\n",
      "Epoch 52/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0842 - accuracy: 0.9636 - val_loss: 0.4542 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.0765 - accuracy: 0.9678 - val_loss: 0.4763 - val_accuracy: 0.8896\n",
      "Epoch 54/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0934 - accuracy: 0.9617 - val_loss: 0.3891 - val_accuracy: 0.8956\n",
      "Epoch 55/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0824 - accuracy: 0.9654 - val_loss: 0.4964 - val_accuracy: 0.8859\n",
      "Epoch 56/100\n",
      "824/824 [==============================] - 28s 34ms/step - loss: 0.0832 - accuracy: 0.9687 - val_loss: 0.4129 - val_accuracy: 0.9041\n",
      "Epoch 57/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 0.4730 - val_accuracy: 0.9029\n",
      "Epoch 58/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0834 - accuracy: 0.9666 - val_loss: 0.4418 - val_accuracy: 0.8871\n",
      "Epoch 59/100\n",
      "824/824 [==============================] - 31s 38ms/step - loss: 0.0768 - accuracy: 0.9699 - val_loss: 0.4744 - val_accuracy: 0.8944\n",
      "Epoch 60/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0660 - accuracy: 0.9718 - val_loss: 0.5882 - val_accuracy: 0.8920\n",
      "Epoch 61/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.0660 - accuracy: 0.9727 - val_loss: 0.4988 - val_accuracy: 0.9041\n",
      "Epoch 62/100\n",
      "824/824 [==============================] - 23s 28ms/step - loss: 0.0726 - accuracy: 0.9727 - val_loss: 0.5344 - val_accuracy: 0.8920\n",
      "Epoch 63/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.5446 - val_accuracy: 0.8883\n",
      "Epoch 64/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0855 - accuracy: 0.9630 - val_loss: 0.4470 - val_accuracy: 0.9017\n",
      "Epoch 65/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0704 - accuracy: 0.9733 - val_loss: 0.4842 - val_accuracy: 0.8981\n",
      "Epoch 66/100\n",
      "824/824 [==============================] - 29s 36ms/step - loss: 0.0754 - accuracy: 0.9678 - val_loss: 0.5195 - val_accuracy: 0.8920\n",
      "Epoch 67/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0700 - accuracy: 0.9715 - val_loss: 0.4862 - val_accuracy: 0.8908\n",
      "Epoch 68/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0603 - accuracy: 0.9745 - val_loss: 0.4632 - val_accuracy: 0.9029\n",
      "Epoch 69/100\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.0861 - accuracy: 0.9648 - val_loss: 0.4619 - val_accuracy: 0.8956\n",
      "Epoch 70/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0585 - accuracy: 0.9751 - val_loss: 0.5190 - val_accuracy: 0.9078\n",
      "Epoch 71/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0546 - accuracy: 0.9745 - val_loss: 0.5024 - val_accuracy: 0.8993\n",
      "Epoch 72/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0666 - accuracy: 0.9705 - val_loss: 0.5540 - val_accuracy: 0.9053\n",
      "Epoch 73/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0692 - accuracy: 0.9718 - val_loss: 0.5863 - val_accuracy: 0.8968\n",
      "Epoch 74/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0692 - accuracy: 0.9708 - val_loss: 0.5325 - val_accuracy: 0.8993\n",
      "Epoch 75/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.0691 - accuracy: 0.9748 - val_loss: 0.5199 - val_accuracy: 0.9029\n",
      "Epoch 76/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0734 - accuracy: 0.9702 - val_loss: 0.4671 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0567 - accuracy: 0.9787 - val_loss: 0.5199 - val_accuracy: 0.9017\n",
      "Epoch 78/100\n",
      "824/824 [==============================] - 24s 30ms/step - loss: 0.0737 - accuracy: 0.9699 - val_loss: 0.6293 - val_accuracy: 0.8968\n",
      "Epoch 79/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0668 - accuracy: 0.9745 - val_loss: 0.4588 - val_accuracy: 0.9017\n",
      "Epoch 80/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0617 - accuracy: 0.9754 - val_loss: 0.5232 - val_accuracy: 0.8968\n",
      "Epoch 81/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0487 - accuracy: 0.9812 - val_loss: 0.5505 - val_accuracy: 0.9041\n",
      "Epoch 82/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0784 - accuracy: 0.9715 - val_loss: 0.4698 - val_accuracy: 0.8859\n",
      "Epoch 83/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.4771 - val_accuracy: 0.9017\n",
      "Epoch 84/100\n",
      "824/824 [==============================] - 25s 31ms/step - loss: 0.0616 - accuracy: 0.9718 - val_loss: 0.4616 - val_accuracy: 0.9017\n",
      "Epoch 85/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.0632 - accuracy: 0.9751 - val_loss: 0.5304 - val_accuracy: 0.8981\n",
      "Epoch 86/100\n",
      "824/824 [==============================] - 29s 35ms/step - loss: 0.0670 - accuracy: 0.9724 - val_loss: 0.5558 - val_accuracy: 0.8920\n",
      "Epoch 87/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0470 - accuracy: 0.9803 - val_loss: 0.7211 - val_accuracy: 0.8956\n",
      "Epoch 88/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0718 - accuracy: 0.9715 - val_loss: 0.5311 - val_accuracy: 0.8871\n",
      "Epoch 89/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0803 - accuracy: 0.9666 - val_loss: 0.5047 - val_accuracy: 0.8968\n",
      "Epoch 90/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0583 - accuracy: 0.9794 - val_loss: 0.5494 - val_accuracy: 0.9017\n",
      "Epoch 91/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.4308 - val_accuracy: 0.9005\n",
      "Epoch 92/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0572 - accuracy: 0.9757 - val_loss: 0.5644 - val_accuracy: 0.9017\n",
      "Epoch 93/100\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.0665 - accuracy: 0.9715 - val_loss: 0.4823 - val_accuracy: 0.8981\n",
      "Epoch 94/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0589 - accuracy: 0.9769 - val_loss: 0.5672 - val_accuracy: 0.8968\n",
      "Epoch 95/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0552 - accuracy: 0.9772 - val_loss: 0.5963 - val_accuracy: 0.8944\n",
      "Epoch 96/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0692 - accuracy: 0.9727 - val_loss: 0.5706 - val_accuracy: 0.8944\n",
      "Epoch 97/100\n",
      "824/824 [==============================] - 26s 32ms/step - loss: 0.0532 - accuracy: 0.9797 - val_loss: 0.5891 - val_accuracy: 0.9029\n",
      "Epoch 98/100\n",
      "824/824 [==============================] - 27s 32ms/step - loss: 0.0505 - accuracy: 0.9797 - val_loss: 0.6572 - val_accuracy: 0.8883\n",
      "Epoch 99/100\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.0702 - accuracy: 0.9730 - val_loss: 0.4251 - val_accuracy: 0.9187\n",
      "Epoch 100/100\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.0533 - accuracy: 0.9766 - val_loss: 0.5469 - val_accuracy: 0.9078\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x) \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# X_final, X_val, y_final, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_final, y_final,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     batch_size=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('inception_case_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "\n",
    "# # Data augmentation setup\n",
    "# datagen = ImageDataGenerator(horizontal_flip=True, height_shift_range=0.2, zoom_range=0.2)\n",
    "\n",
    "# # Generate 200 augmented images for each class\n",
    "# X_augmented = []\n",
    "# y_augmented = []\n",
    "# for class_name in class_names:\n",
    "#     class_idx = class_names.index(class_name)\n",
    "#     class_images = X_train[y_train == class_idx]\n",
    "#     class_labels = y_train[y_train == class_idx]\n",
    "    \n",
    "#     augmented_images = datagen.flow(class_images, class_labels, batch_size=1, shuffle=False)\n",
    "    \n",
    "#     for _ in range(200):\n",
    "#         aug_img, aug_label = augmented_images.next()\n",
    "#         X_augmented.append(aug_img[0])\n",
    "#         y_augmented.append(aug_label[0])\n",
    "\n",
    "# X_augmented = np.array(X_augmented)\n",
    "# y_augmented = np.array(y_augmented)\n",
    "\n",
    "# X_combined = np.concatenate((X_train, X_augmented), axis=0)\n",
    "# y_combined = np.concatenate((y_train, y_augmented), axis=0)\n",
    "\n",
    "# X_final2, X_val2, y_final2, y_val2 = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.6)(x) \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# model2.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history2 = model2.fit(\n",
    "#     X_final2, y_final2,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val2, y_val2),\n",
    "#     batch_size=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save('inception_case_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history2.history['loss'])\n",
    "# plt.plot(history2.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history2.history['accuracy'])\n",
    "# plt.plot(history2.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "\n",
    "# base_dir = 'C:/brain_tumor/version2/notebook/Training'\n",
    "# gen_dir = 'C:/brain_tumor/version2/notebook/generated_dataset'\n",
    "# class_names = ['glioma', 'meningioma', 'pituitary']\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "# X_generated = []\n",
    "# y_generated = []\n",
    "\n",
    "# for label, class_name in enumerate(class_names):\n",
    "#     class_dir = os.path.join(base_dir, class_name)\n",
    "#     gen_class_dir = os.path.join(gen_dir, class_name)\n",
    "#     for img_name in os.listdir(class_dir):\n",
    "#         img_path = os.path.join(class_dir, img_name)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         X.append(img)\n",
    "#         y.append(label)\n",
    "#     for image_name in os.listdir(gen_class_dir):\n",
    "#         image_path = os.path.join(gen_class_dir, image_name)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.resize(image, (128, 128))\n",
    "#         X_generated.append(image)\n",
    "#         y_generated.append(label)\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# X_generated = np.array(X_generated)\n",
    "# y_generated = np.array(y_generated)\n",
    "\n",
    "# X = X.astype('float32') / 255.0\n",
    "# X_generated = X_generated.astype('float32') / 255.0\n",
    "\n",
    "# X_train = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_train])\n",
    "# X_test = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_test])\n",
    "# X_generated = np.array([preprocess_input(cv2.resize(img, (128, 128))) for img in X_generated])\n",
    "\n",
    "# X_train_combined = np.concatenate((X_train, X_generated), axis=0)\n",
    "# y_train_combined = np.concatenate((y_train, y_generated), axis=0)\n",
    "\n",
    "# shuffle_indices = np.random.permutation(len(X_train_combined))\n",
    "# X_train_combined_shuffled = X_train_combined[shuffle_indices]\n",
    "# y_train_combined_shuffled = y_train_combined[shuffle_indices]\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "# x = Dropout(0.7)(x)  \n",
    "# predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# model1 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# X_final1, X_val1, y_final1, y_val1 = train_test_split(X_train_combined_shuffled, y_train_combined_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "# model1.compile(optimizer=Adam(learning_rate=0.0002), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history1 = model1.fit(\n",
    "#     X_final1, y_final1,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val1, y_val1),\n",
    "#     batch_size=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('inception_case_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history1.history['loss'])\n",
    "# plt.plot(history1.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history1.history['accuracy'])\n",
    "# plt.plot(history1.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
